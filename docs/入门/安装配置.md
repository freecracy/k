# 安装配置

## 建议

```shell
systemctl disable firewalld
systemctl stop  firewalld # 禁用防火墙
setenforce 0 # 关闭 selinux /etc/sysconfig/selinux selinux=disable
```

## 使用 kubeadm 安装

### 安装

```yaml
[kubernetes]
name =
baseurl =
enabled = 1
gpgcheck = 0
```

```shell
yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes
systemctl enable docker & systemctl start docker
systemctl enable kubelet & systemctl start kubelet
```

### 配置

```shell
kubeadm config upload from-file # 配置文件上传到集群中生成 configmap
kubeadm config upload from-flags # 由配置参数生成 configmap
kubeadm config view # 查看当前集群中配置值
kubeadm config print init-defaults # 输出 kubeadm init 默认参数的文件内容
kubeadm config print join-defaults #
kubeadm config migrate # 在新旧版本之间进行配置转换
kubeadm config images list # 列出所需的镜像列表
kubeadm config config images pull # 拉取镜像到本地

kubeadm config print init-defaults > init.default.yaml # 对生成对文件修改即可 init-config.yaml
```

### 下载相关镜像

#### docker 加速

```shell
echo '{"registry-mirrors":["https://registry.docker-cn.com"]}' > /etc/docker/daemon.json # 重启docker
```

#### 下载

```shell
kubeadm config images pull --config=init-config.yaml
```

### 安装 master

```shell
kubeadm init # 一键安装 k8s 的 master,此时不具备网络功能,需要单独安装插件
kubeadm init --config=init-config.yaml # 集群控制面初始化,等待 master 安装成功
# 根据提示复制配置文件到用户的 home 目录
# master 上安装了 k8s,但是集群内还没有可用的工作 node,并缺乏对容器网络的配置

kubectl get -n kube-system configmap # 验证 configmap
```

### 安装 node,加入集群

```shell
# 同 master 初始化
# 修改配置 apiserverEndpoint master 地址 token 和 tlsbootstraptoken 来自上面 master 最后一行提示
kubeadm join --config=join-config.yaml  # join 命令加入集群
kubectl taint nodes --alll node-role.kubernets.io/master # 上传 node 的 label 让 master 称为一个 node,安装一个单机 all-in-one 的 k8s 环境
```

### 安装网络插件

```shell
kugectl get nodes # 查看 master 状态为 notready,因为还没安装网络插件
kubectl apply  f https // cloud.Weave.works/k s/net? k 8 s - version = s  (kubectl  version I base64 Itr-d \n!)
```

### 验证

```shell
kubectl get pods --alll-namespaces # 查看所有 pod 正常
kubectl --namespace=kube-system describe pod podname # 如果有状态错误的 pod,可以查看错误原因
kubeadm reset # 将主机恢复原状,重新安装
```

## 以二进制文件方式安装

k8s 主要服务程序都可以通过直接运行二进制文件加上启动参数完成运行.在 master 上需要部署 etcd、kube-apiserver、kube-controller-manager、kube-scheduler 服务进程,在工作 node 上需要部署 docker、kubelet 和 kube-proxy 服务进程.

| 文件名                             | 说明                                  |
| ---------------------------------- | ------------------------------------- |
| kube-apiserver                     | 主程序                                |
| kube-apiserver.docker_tag          | docker 镜像 tag                       |
| kube-apiserver.tar                 | apiserver docker 镜像文件             |
| kube-controller-manager            | 主程序                                |
| kube-controller-manager.docker_tag | 镜像tag                               |
| kube-controller-manager.tar        | 镜像文件                              |
| kube-scheduler                     |                                       |
| kube-scheduler.docker_tag          |                                       |
| kube-scheduler.tar                 |                                       |
| kubelet                            |                                       |
| kube-proxy                         |                                       |
| kube-proxy.tar                     |                                       |
| kubectl                            |                                       |
| kubeadm                            |                                       |
| hyperkube                          | 包含了所有服务的程序,可以启动任一服务 |
| clout-controller-manager           | 与云厂商对接的 controller             |
| apiextensions-apiserver            | 实现自定义资源对象扩展的apiserver     |

将二进制文件复制到 /usr/bin 目录下,在 /usr/lib/system/system 目录下创建服务配置.

### etcd 服务

将 etcd 和 etcdctl 复制到 bin 目录.并配置 systemd.

```yaml
[Unit]
Description=Etcd Server
After=network target

[Service]
ype=simple
Workingdirectory=/var/lib/etcd/ # etcd 数据保存目录,需要在启动 etcd 前创建
Environmentfile=-/etc/etcd/etcd.Conf
Execstart=/usr/in/etcd

[Install]
Wantedby=Multi-user target
```

```shell
systemctl daemon-reload
systemctl enable etcd.service
systemctl start etcd.service
etcdctl endpoint health # 验证 etcd 是否正确启动
```

### kube-apiserver 服务

将 kube-apiserver、kube-controller-manager、kube-scheduler 复制到 /usr/bn 目录.

设置 /usr/lib/systemd/system/kube-apiserver.service.

```yaml
[Uniti]
Description=Kubernetes API Server
 Documentation=https: / / github. Com / gooqlecloudplatform / kubernetes
 After=etcd.service
 Wants=etcd.Service

 [Service]
Environmentfile=/etc/kubernetes/apiserver
Execstart=/usr/bin/Kube-apiserver SKUBE_API_ARGS # cat /etc/kubernetes/apiserver
Restart=On-failure
Iype=notify
LIMITNOFILE=65536

 [Install]
 Wantedby=Multi-user.target
```

### 启动参数

1. --etc-servers : 指定 etcd 服务的 url
2. --storage-backend : 指定 etcd 版本
3. --insecure-bind-address : api server 绑定主机的非安全 ip 地址,设置 0.0.0.0 表示绑定所有 ip 地址
4. --insecure-port : api server 绑定主机非安全端口,默认 8989
5. --service-cluster-ip-range : 集群中 service 的虚拟 ip 地址范围,不能与无力机 ip 地址有重合,如 169.169.0.0/16
6. --service-node-port-range : 集群中 service 可使用的物理机端口号范围,默认 3000~32767
7. --enable-admission-plugins : 集群的准入控制设置
8. --logtostderr : 设置为 false 表示将日志写入文件不写入 stderr
9. --log-dir : 日志目录
10. --v : 日志级别

### kube-controller-manager 服务

kube-controller-manager 服务依赖 kube-apiserver 服务.

设置 /usr/lib/systemd/system/kube-controller-manager.service

```yaml

```

### kube-scheduler 服务

kube-scheduler 依赖 kube-apiserver.

### node 上 kubelet、kube-proxy 服务

需要先安装 docker
